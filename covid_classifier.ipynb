{"cells":[{"cell_type":"code","metadata":{"id":"7H6He3Pdu3wW","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16, ResNet50V2, DenseNet121\n","from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, BatchNormalization, Activation\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, f1_score, precision_score, recall_score, classification_report\n","from datetime import datetime\n","import pickle as pkl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pk65muHJz31h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592707392862,"user_tz":-420,"elapsed":7317,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"54216f19-00d5-4305-d358-6a5c7a53dfa7"},"source":["%cd /content/drive/My Drive/hackathon"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7tOAS_yRQzX","colab_type":"text"},"source":["# Load and preprocess data"]},{"cell_type":"code","metadata":{"id":"x0QxyCmoryjz","colab_type":"code","colab":{}},"source":["def to_one_hot(y):\n","  if y == 'covid':\n","    return np.array([1, 0, 0])\n","  elif y == 'normal':\n","    return np.array([0, 1, 0])\n","  elif y == 'pneumonia':\n","    return np.array([0, 0, 1])\n","  else:\n","    raise ValueError(y + ' does not belong to any class')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFhdFGHJ1oNy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1592672964967,"user_tz":-420,"elapsed":22427,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"4dde86ce-7feb-43b5-f543-02a9596bcc5d"},"source":["# Load and preprocess train data\n","train_data = []\n","train_label = []\n","train_path = '/content/drive/My Drive/hackathon/images/train'\n","#train_path = '/content/drive/My Drive/hackathon/images/chest-crops/train'\n","\n","for folder in os.listdir(train_path):\n","  for img in tqdm(os.listdir(os.path.join(train_path, folder))):\n","    # read, convert channels, and resize images\n","    image = cv2.imread(os.path.join(train_path, folder, img))\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224))\n","\n","    # Extract labels\n","    label = folder\n","\n","    # Append to lists\n","    train_data.append(image)\n","    train_label.append(label)\n","\n","# Convert to numpy array and normalize images\n","x_train = np.array(train_data)/255.\n","y_train = np.array(train_label)\n","print(x_train.shape, y_train.shape)\n","\n","# convert y to one-hot\n","y_train_one_hot = np.array([to_one_hot(y) for y in y_train])\n","y_train_one_hot.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJuVvpWr78qp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1592672969695,"user_tz":-420,"elapsed":3665,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"09403842-913d-420c-8fc2-ddfb1d192374"},"source":["# Load and preprocess validation data\n","val_data = []\n","val_label = []\n","val_path = '/content/drive/My Drive/hackathon/images/val'\n","#val_path = '/content/drive/My Drive/hackathon/images/chest-crops/val'\n","\n","for folder in os.listdir(val_path):\n","  for img in tqdm(os.listdir(os.path.join(val_path, folder))):\n","    # read, convert channels, and resize images\n","    image = cv2.imread(os.path.join(val_path, folder, img))\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224))\n","\n","    # Extract labels\n","    label = folder\n","\n","    # Append to lists\n","    val_data.append(image)\n","    val_label.append(label)\n","\n","# Convert to numpy array and normalize images\n","x_val = np.array(val_data)/255.\n","y_val = np.array(val_label)\n","print(x_val.shape, y_val.shape)\n","\n","# convert y to one-hot\n","y_val_one_hot = np.array([to_one_hot(y) for y in y_val])\n","y_val_one_hot.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRE11ee3tgfH","colab_type":"code","colab":{}},"source":["# Save to pkl\n","with open('x_train.pkl', 'wb') as file:\n","  pkl.dump(x_train, file)\n","with open('y_train.pkl', 'wb') as file:\n","  pkl.dump(y_train, file)\n","with open('y_train_one_hot.pkl', 'wb') as file:\n","  pkl.dump(y_train_one_hot, file)\n","\n","with open('x_val.pkl', 'wb') as file:\n","  pkl.dump(x_val, file)\n","with open('y_val.pkl', 'wb') as file:\n","  pkl.dump(y_val, file)\n","with open('y_val_one_hot.pkl', 'wb') as file:\n","  pkl.dump(y_val_one_hot, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTyumyR744V_","colab_type":"code","colab":{}},"source":["# Load from pkl\n","with open('x_train.pkl', 'rb') as file:\n","  x_train = pkl.load(file)\n","with open('y_train.pkl', 'rb') as file:\n","  y_train = pkl.load(file)\n","with open('y_train_one_hot.pkl', 'rb') as file:\n","  y_train_one_hot = pkl.load(file)\n","\n","with open('x_val.pkl', 'rb') as file:\n","  x_val = pkl.load(file)\n","with open('y_val.pkl', 'rb') as file:\n","  y_val = pkl.load(file)\n","with open('y_val_one_hot.pkl', 'rb') as file:\n","  y_val_one_hot = pkl.load(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d7nPwsDpE94","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1592673334123,"user_tz":-420,"elapsed":28435,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"fd303b34-53cc-45be-aa5a-be262257195b"},"source":["# Cropped version: Load and preprocess train data\n","train_data_crop = []\n","train_label_crop = []\n","#train_path = '/content/drive/My Drive/hackathon/images/train'\n","train_path = '/content/drive/My Drive/hackathon/images/chest-crops/train'\n","\n","for folder in os.listdir(train_path):\n","  for img in tqdm(os.listdir(os.path.join(train_path, folder))):\n","    # read, convert channels, and resize images\n","    image = cv2.imread(os.path.join(train_path, folder, img))\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224))\n","\n","    # Extract labels\n","    label = folder\n","\n","    # Append to lists\n","    train_data_crop.append(image)\n","    train_label_crop.append(label)\n","\n","# Convert to numpy array and normalize images\n","x_train_crop = np.array(train_data_crop)/255.\n","y_train_crop = np.array(train_label_crop)\n","print(x_train_crop.shape, y_train_crop.shape)\n","\n","# convert y to one-hot\n","y_train_one_hot_crop = np.array([to_one_hot(y) for y in y_train_crop])\n","y_train_one_hot_crop.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSrzDNBzpbu3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1592673334595,"user_tz":-420,"elapsed":27583,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"00277ce5-69fc-45af-bfb0-6437a0588177"},"source":["# Cropped version: Load and preprocess train data\n","val_data_crop = []\n","val_label_crop = []\n","#val_path = '/content/drive/My Drive/hackathon/images/val'\n","val_path = '/content/drive/My Drive/hackathon/images/chest-crops/val'\n","\n","for folder in os.listdir(val_path):\n","  for img in tqdm(os.listdir(os.path.join(val_path, folder))):\n","    # read, convert channels, and resize images\n","    image = cv2.imread(os.path.join(val_path, folder, img))\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224))\n","\n","    # Extract labels\n","    label = folder\n","\n","    # Append to lists\n","    val_data_crop.append(image)\n","    val_label_crop.append(label)\n","\n","# Convert to numpy array and normalize images\n","x_val_crop = np.array(val_data_crop)/255.\n","y_val_crop = np.array(val_label_crop)\n","print(x_val_crop.shape, y_val_crop.shape)\n","\n","# convert y to one-hot\n","y_val_one_hot_crop = np.array([to_one_hot(y) for y in y_val_crop])\n","y_val_one_hot_crop.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9MwWWXMuPXs","colab_type":"code","colab":{}},"source":["# Cropped: Save to pkl\n","with open('x_train_crop.pkl', 'wb') as file:\n","  pkl.dump(x_train_crop, file)\n","with open('y_train_crop.pkl', 'wb') as file:\n","  pkl.dump(y_train_crop, file)\n","with open('y_train_one_hot_crop.pkl', 'wb') as file:\n","  pkl.dump(y_train_one_hot_crop, file)\n","\n","with open('x_val_crop.pkl', 'wb') as file:\n","  pkl.dump(x_val_crop, file)\n","with open('y_val_crop.pkl', 'wb') as file:\n","  pkl.dump(y_val_crop, file)\n","with open('y_val_one_hot_crop.pkl', 'wb') as file:\n","  pkl.dump(y_val_one_hot_crop, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"THF3JCZu5b-I","colab_type":"code","colab":{}},"source":["# Cropped: Load from pkl\n","with open('x_train_crop.pkl', 'rb') as file:\n","  x_train_crop = pkl.load(file)\n","with open('y_train_crop.pkl', 'rb') as file:\n","  y_train_crop = pkl.load(file)\n","with open('y_train_one_hot_crop.pkl', 'rb') as file:\n","  y_train_one_hot_crop = pkl.load(file)\n","\n","with open('x_val_crop.pkl', 'rb') as file:\n","  x_val_crop = pkl.load(file)\n","with open('y_val_crop.pkl', 'rb') as file:\n","  y_val_crop = pkl.load(file)\n","with open('y_val_one_hot_crop.pkl', 'rb') as file:\n","  y_val_one_hot_crop = pkl.load(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WlAbtBSe8nP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592703654394,"user_tz":-420,"elapsed":4406,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"2c393c46-1baf-47a7-f95d-9da62731405a"},"source":["# Create uncropped train+val\n","x_trainval = np.concatenate((x_train, x_val))\n","x_trainval.shape\n","\n","with open('x_trainval.pkl', 'wb') as file:\n","  pkl.dump(x_trainval, file)\n","\n","y_trainval_one_hot = np.concatenate((y_train_one_hot, y_val_one_hot))\n","y_trainval_one_hot.shape\n","\n","with open('y_trainval_one_hot.pkl', 'wb') as file:\n","  pkl.dump(y_trainval_one_hot, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqMJ4sXbjSWD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592710382920,"user_tz":-420,"elapsed":2119,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"32f7fa65-e407-4cd9-cbe8-8a60eb014602"},"source":["# Create cropped train+val\n","x_trainval_crop = np.concatenate((x_train_crop, x_val_crop))\n","x_trainval_crop.shape\n","\n","with open('x_trainval_crop.pkl', 'wb') as file:\n","  pkl.dump(x_trainval_crop, file)\n","\n","y_trainval_one_hot_crop = np.concatenate((y_train_one_hot_crop, y_val_one_hot_crop))\n","y_trainval_one_hot_crop.shape\n","\n","with open('y_trainval_one_hot_crop.pkl', 'wb') as file:\n","  pkl.dump(y_trainval_one_hot_crop, file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e4KLopKoSMmW","colab_type":"text"},"source":["# Model\n","- VGG 16\n","- ResNet50V2\n","- DenseNet121"]},{"cell_type":"code","metadata":{"id":"V_zQISJODtl3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593061468279,"user_tz":-420,"elapsed":14341,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"becb3887-feef-44d6-bad2-dbff2f36dc62"},"source":["# load the VGG16 network, ensuring the head FC layer sets are left off\n","#baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","baseModel = ResNet50V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","#baseModel = DenseNet121(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","\n","# construct the head of the model that will be placed on top of the the base model\n","headModel = baseModel.output\n","headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n","headModel = Flatten(name=\"flatten\")(headModel)\n","headModel = Dense(64, activation=\"relu\")(headModel)\n","headModel = Dropout(0.5)(headModel)\n","headModel = Dense(3, activation=\"softmax\")(headModel)\n","\n","# place the head FC model on top of the base model (this will become the actual model we will train)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","\n","# loop over all layers in the base model and freeze them so they will *not* be updated during the first training process\n","for layer in baseModel.layers:\n","\tlayer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yO7bL1a03LtX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593061549131,"user_tz":-420,"elapsed":1114,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"325f2ffa-018b-4bf2-84f2-ce1248a8cacc"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTw5Gs7SSc2I","colab_type":"text"},"source":["Have tested connecting deeper network but performs worse."]},{"cell_type":"code","metadata":{"id":"8rX6K_PB5ASg","colab_type":"code","colab":{}},"source":["# # load the VGG16 network, ensuring the head FC layer sets are left off\n","# # baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","# baseModel = ResNet50V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","\n","# # construct the head of the model that will be placed on top of the the base model\n","# headModel = baseModel.output\n","# headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n","# headModel = Flatten(name=\"flatten\")(headModel)\n","\n","# headModel = Dense(1024)(headModel)\n","# headModel = BatchNormalization()(headModel)\n","# headModel = Activation('relu')(headModel)\n","# headModel = Dropout(0.5)(headModel)\n","\n","# headModel = Dense(512)(headModel)\n","# headModel = BatchNormalization()(headModel)\n","# headModel = Activation('relu')(headModel)\n","# headModel = Dropout(0.5)(headModel)\n","\n","# headModel = Dense(256)(headModel)\n","# headModel = BatchNormalization()(headModel)\n","# headModel = Activation('relu')(headModel)\n","# headModel = Dropout(0.5)(headModel)\n","\n","# headModel = Dense(128)(headModel)\n","# headModel = BatchNormalization()(headModel)\n","# headModel = Activation('relu')(headModel)\n","# headModel = Dropout(0.5)(headModel)\n","\n","# headModel = Dense(64)(headModel)\n","# headModel = BatchNormalization()(headModel)\n","# headModel = Activation('relu')(headModel)\n","# headModel = Dropout(0.5)(headModel)\n","\n","# headModel = Dense(3, activation=\"softmax\")(headModel)\n","\n","# # place the head FC model on top of the base model (this will become the actual model we will train)\n","# model = Model(inputs=baseModel.input, outputs=headModel)\n","\n","# # loop over all layers in the base model and freeze them so they will *not* be updated during the first training process\n","# for layer in baseModel.layers:\n","# \tlayer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0J3OF3e8Sv7X","colab_type":"text"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"2mwUxGhUS2RL","colab_type":"text"},"source":["- Set hyperparameters\n","- Compile\n","- Create callbacks to save only the best checkpoint\n","- Augment data\n","- Train"]},{"cell_type":"code","metadata":{"id":"Dxv3nT0bEL8E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":725},"executionInfo":{"status":"ok","timestamp":1592712938626,"user_tz":-420,"elapsed":188868,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"5cd445b0-672f-43ce-f538-ec8d5d990f3e"},"source":["# Set hyperparameters\n","INIT_LR = 1e-3\n","EPOCHS = 20\n","BS = 8\n","\n","# compile our model\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n","\n","# Save only best checkpoints\n","time = datetime.now().strftime('_%H-%M-%S')\n","\n","checkpoint_filepath_best = 'resnet50_all_checkpoints_best'+time+'/'\n","os.mkdir(checkpoint_filepath_best)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath_best,\n","    save_weights_only=False,\n","    monitor='val_accuracy',# val_auc_4 val_accuracy\n","    mode='max',\n","    save_best_only=True)\n","\n","# train the head of the network\n","trainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\") # , horizontal_flip=True, vertical_flip=True\n","\n","print(\"[INFO] training head...\")\n","H = model.fit_generator(\n","\ttrainAug.flow(x_trainval_crop, y_trainval_one_hot_crop, batch_size=BS),\n","\tsteps_per_epoch=len(x_trainval_crop) // BS,\n","\tvalidation_data=(x_val, y_val_one_hot),\n","\tvalidation_steps=len(y_train_one_hot) // BS,\n","\tepochs=EPOCHS)#,\n","  callbacks=[model_checkpoint_callback]) # , cp_callback"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBrcX6BWacGC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1592708132014,"user_tz":-420,"elapsed":8736,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"155b0037-70e4-4db0-ef37-86ebeaabdff8"},"source":["# Plot training history\n","acc = H.history['accuracy']\n","val_acc = H.history['val_accuracy']\n","loss=H.history['loss']\n","val_loss=H.history['val_loss']\n","epochs_range = range(EPOCHS)\n","\n","plt.figure(figsize=(16, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59IVIUHVTuV3","colab_type":"text"},"source":["# Benchmark\n","Focus mainly on F1-score"]},{"cell_type":"code","metadata":{"id":"HgTyROYueHXk","colab_type":"code","colab":{}},"source":["def benchmark(model, save_path, x_val, y_val_one_hot):\n","  # Create prediction\n","  predictions = model.predict(x_val)\n","\n","  # Create Confusion Matrix\n","  cm = confusion_matrix(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1))\n","\n","  # Plot Confusion Matrix\n","  plot_confusion_matrix(cm, normalize=False, target_names=['covid', 'normal', 'pneumonia'], title=\"Confusion Matrix\", path=save_path)\n","\n","  # Print classification_report\n","  report = classification_report(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1), target_names=['covid','normal','pneumonia'], output_dict=True)\n","  avg_f1 = (report['covid']['f1-score'] + report['normal']['f1-score'] + report['pneumonia']['f1-score']) / 3\n","  avg_acc = report['accuracy']\n","  print(classification_report(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1), target_names=['covid','normal','pneumonia']))\n","  print('Average F1-Score =', avg_f1)\n","\n","  # Save avg_f1 and avg_acc to txt file\n","  with open(save_path+'benchmark.txt', 'w') as file:\n","    file.write('Average F1-Score: %.4f\\nAverage Accuracy: %.4f' % (avg_f1, avg_acc))\n","    file.write(str(report))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbMxa1wqemGI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":657},"executionInfo":{"status":"ok","timestamp":1592708155412,"user_tz":-420,"elapsed":21254,"user":{"displayName":"Cheese Bacon&Chicken&Beef","photoUrl":"","userId":"02715863801569203458"}},"outputId":"535598b5-cd6b-4252-9089-28178edce3f7"},"source":["# Benchmark the model\n","benchmark(tf.keras.models.load_model(checkpoint_filepath_best), save_path=checkpoint_filepath_best, x_val=x_val, y_val_one_hot=y_val_one_hot)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YA5mcgfGLVp_","colab_type":"code","colab":{}},"source":["def plot_confusion_matrix(cm, target_names, path, title='Confusion matrix', cmap=None, normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize = 'xx-large')\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    plt.savefig(path+'confusion_matrix.png')\n","    plt.show()"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"covid_classifier.ipynb","provenance":[{"file_id":"1z7qe7EXrqfGa8RnVfKe0CCUQ96g5uIKI","timestamp":1593084701891}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}